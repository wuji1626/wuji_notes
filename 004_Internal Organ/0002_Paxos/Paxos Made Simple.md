#Paxos Made Simple
[TOC]

##1 介绍
Paxos是容错的分布式系统  
Paxos本质上一致性算法，或者叫共识算法（consensus algorithm）
##2 一致性算法
###2.1 问题描述
假设一系列进程提交数据。一致性算法确保其中一个提交的数据被采纳。如果没有数据提交，没有数据被采纳。一旦数据被采纳，系统中所有进程都能感知到选择的数据。一致性算法需要满足的需求有：
- 只有一个提交的数据值被采纳
- 唯一的数据值被采纳
- 进程只有在提交数据被采纳时才能感知到
在一致性算法中需要定义三类角色描述该算法：提交者（proposer）、接受者（acceptor）、感知者（learner）。一个进程在一次处理中可能扮演多个角色，这种进程与角色的映射在论文中没有体现  

假设系统中的代理之间需要消息传递。采用常规异步通信或者称拜占庭模式：  
- 代理的操作可以按任意速度，可能由于代理的停止或者重启而失败。在所有代理提交的值被采纳后进行失败重启。这样记录代理失败或者重启时的状态非常重要  
- 消息可以是任意长度。消息可以被传递、被提交也可以被丢弃，但是不能被毁坏  

###2.2 采纳值（Choosing a Value）
**单一接受者模式**：当提交者提交信息给接受者，接受者只接受自己所接受到的第一个值。但是单一接受者面临巨大问题：一旦接受者宕掉，后续的处理都无法进行  

**多接受者模式**：提交者提交数值给多个接受者。接受者可以接受提交的值。当接受者数量达到一定量，提交的数据就称为被接受。为确定一个数值被接受，确保代理中的大多数是该数值。在两个是大多数的代理，至少拥有1个相同的接收器，这样接收器可以接受大部分的数值  

如果失败信息或者消息缺失的情况下，我们需要选择提交值，建议：
1. 接收器必须接受他收到的第一个提交的值（P1）  
这种方案会产生问题。不同的值可能被不同的提交者同时提交数据。这样会导致，每个接收器都接受了一个数值，但是不是单个的值被接收器中的大部分被接受。这种场景，即使两个提交值，每个值都被一半的接收器接受，单个接收器的失败，使接收器无法感知哪个数值被选择  
上面观点暗示每个接收器需要接受多个提交值。需要追踪不同的提交值，接受者可能接受到一系列提交数据。每个数据中都包括提交的编号以及数值。为了避免混乱，一些不同的提交有不同的编号。这个实现方法都只是假设。  
可以接受多个提交的值，但是这些值必须相同。
2. 如果一个提交值v被选择，则所有提交编号大于该提交值的提交，并且值为v的都被选择（P2）  
*这个功能需要在提交值信息中有一个提交编号*  
这种通过提交值得流水号顺序的方式，可以帮助关键属性只有一个提交值被选择  
3. 如果一个提交包含v值被选中，所有提交流水号大于该编号的值可以被任意的接收器接收
——$P2^a$  
4. 如果提交包含v被选中，所有流水号大于它的由其他提交者提交的提交项目都包含值v  
——$P2^b$  
这是保证既保证P1又保证P2a的推论  
以上推论满足如下推论关系：  
$P2^b  →  P2^a  →  P2$
5. 对于任意的v和n，如果提交值包含v，并且编号为n，有一个集合S组成大多数接受者，结合中的成员没有接受小于n的提交，或者v是提交中编号最大的提案，S中接受的所有提案的编号都小于n  
——$P2^c$
**一个提案者想要提交编号为n的提案，必须先学习小于n的，被大多数接受者接受的提案**。提案者要求，接受者不接受任何编号小于n的提案  
	1.提案者选择获得一个新提案值n，然后向所有接受者发送请求（初始请求init request），请求回应：①不再接受提案值小于n的提案；②接受提案编号小于n的提案中编号最大的值
	2.如果提案者接受到多数接受者回应，则它将提交一个编号为n，值为v的提案。值为v的提案是所有返回结果的接受者中编号最大的，或者如果在响应者没有任何提案时，将随机选择一个提案值
提案者提交提案时，向接受者集合发送**接受提案请求**（accept request），接受者集合可能不是之前发送初始请求的响应者。*以上就是提案者算法*  
关于接受者，可以收到提案者两种请求：①准备请求（prepare request）；②接受请求（accept request）。
>学习已经接受的提案容易，预测未来接受的提案难
6. 接收器接受编号为n的提案，当且仅当准备请求的回应中没有比n大的编号
——$P1^a$  
$P1^a \supset P1$  

以上完成了假设提案编号唯一的假设下，选择提案的算法。以下是一些优化：  
当接受者接到一个编号为n的请求，但它已经回应了了比n大的准备请求，它将忽略该提案；当接受者已经接受了该提案时，请求也被忽略  
这种优化下，接受者只记录接受的最大编号的提案，这其中包括两种情况：  
1. 已经接受提案编号的最大值  
2. 已经回应的准备请求编号  

由于$P2^c$要保证，接受者需要记录该信息，以便在失败后进行重启。需要注意：提案者不需要记录信息，因为它们的每个提案都有新提案编号  

综合提案与接受两个动作，将算法总结成两个阶段：  
**Phase 1.**  
（a）提案者选择提案编号n，发送一个准备请求（prepare request）同步带有编号n，发送给大多数的接受者  
（b）接受者接到编号为n的准备请求，并且比其他它已经回复的准备请求编号值都大，它将作出承诺，承诺不再接受编号小于n的请求，之前的提案中最大的编号的提案被接受  
**Phase 2.**  
（a）提案者收到大多数接受者编号为n的准备请求的响应，之后向之前大多数接受者集合发送接受请求（accept request），请求中包括编号n及值v，v是呼应中编号最大的提案的值，当没有任何提案时，可以是任意值  
（b）如果接受者收到编号为n的接受请求时，它将接受请求，除非已经响应了编号比该接受编号更大的准备请求  

提交者可以进行多提案提交，不过每个提案都需要遵从Paxos算法。提交者也可以在任何时候放弃提案。（甚至可以在请求发送到目标端之前很长时间，提案就已经被撤销，同样能够保证正确性）。为了提高效率，在接受者收到有更大编号的提案提交时，就可以放弃提案。同样，接受者在遇到已经响应过更高编号的提案或者已经接受过该编号的请求时，需要向提案者返回信息，以便提案者放弃提案。这只关乎性能，无关于正确性  

###2.3 学习选择值（Learning a Chosen Value）  
为了学习提案值的选择，学习者需要感知到提案被大多数接受者接受。明显有一个算法，在接受者接受提案时，反馈给所有学习者，将提案发给他们。这种方案令学习者尽早感知被选定的值，但是这要求每个接受者向每个学习者编号  

非拜占庭将军失败（non-Byzantine failure）假设：接受者向特定的学习者传递它们接受信息。当决定接受某个值时，接受者交替向其他学习者发送通知。这种机制学习者需要一个额外轮次发现被选择的值。这种机制同样是不可靠的，因为特定的学习桌也有可能会宕机。为了保证可靠性，要求响应数量等于接受者数量与学习者数量  

通常情况，接受者会向一组特定的学习者发送选择值的消息。这种方式将会增加通信的复杂度  

由于消息的丢失，选择值的消息，可能没有学习者感知到。虽然学习者可以主动拉取选择值的信息，同样因为失效，可以让学习者无法获取接受者是否接受了某个提案的信息。这种情况下，学习者只有在新提案被选择时才有可能感知到值的提交活动。如果学习者想感知某值是否被接受，它需要通过提议算法提交一个提议  

###2.4 前进（Progress）
会有一种场景：两个提案者不断提交提案，但是没有任何一个提案被接受  
提案者之间的互相制约会导致提案一直无法被接受  

为了保证系统前进，某个特定提案者必须被选举出来，作为唯一提案者，进行提案。如果特定提案者可以与大多数接受者通信成功，如果它的提案编号比其他已采用的提案编号都大，这样就能促成一次提案。在不断丢弃提案重试过程中，提案者一定能找到一个比已有提案编号都大的提案最终提交成功  

如果系统工作正常，一定能够选择出一个特定的提案者。Fischer、Lynch和Patterson的著名研究结果表明：可靠的选举算法必须采用。选择算法可以是随机算法或者实时算法（如超时算法（超时重传算法？））。需要注意：无论选举成功失败，都有保障安全性  
###2.5 实现（Implementation）
Paxos算法假定是一系列网络状执行过程。在算法的共识中，每个进程都分别扮演：提案者、接受者和学习者三个角色。算法要选定一个leader，扮演特定提案者和特定学习者的角色。算法精确使用的常规消息。特别是返回消息，需要打一致的提案编号避免混乱。稳定的存储、失败保护确保接受者接受的信息都能被记录。接受者记录它的接受响应报文到稳定存储，之后在进行实际的反馈  

所有的机制都是为了确保没有两个被接受的提案带有相同的编号。不同的提交者选择互斥的编号集合，所以不同的提案者会生成的不同不同的提案编号。每个提案者都存储最大的提案编号，在提交新提案时，生成一个比目前编号更大的编号  

##3 状态机的实现
实现分布式系统的最简单的方式是：将客户端的命令收集到中央服务器上。服务器可以看做是一个顺序执行客户端命令的状态机。状态机有一个当前状态，它按步骤执行客户端输入的命令，产出输出并且更新状态。  

单中心服务的实现会产生单点故障。使用服务器集合，每个服务端都独立实现状态机。由于状态机具有决定性作用，如果所有使用相同的命令队列，所有服务器将都使用相同的状态队列和输出。  

为确保所有服务器执行相同的状态机队列，实现了队列，对应算法中的不同实例。每个实例对应一个状态机。每个实例上的主机共同扮演提交者、接受者和学习者的角色。  

**鸿沟（gap）**  
普通操作中，一个主机被推选为leader，为所有实例提交提案。客户端向leader发送请求，leader决定每个命令在队列上出现的位置。如：一个leader决定一个客户端命令是135号命令，它会将该命令编程算法中第135个实例。出现失败的情况是，集群中有其他节点认为自己是leader发布了同样的135号命令。但是算法确保了最多只有一个135号提案被执行  

这种方法的效果是：提交的数值，只有在第2阶段才被选择。第1阶段只是决定是选择了一个值或者提交一个任意值  

新leader是所有实例的学习者。leader应该了解最多的最近接受的命令。假设：leader知道1~134,138,139命令，选择值的实例1~134,138,139。之后执行135~137以及大于139的实例。假设这些实例的输出结果决定了实例135、140的提案值。leader之后执行135、140的第2阶段，因此选择命令135,140  

现在，leader可以和其他主机一样执行1~135的命令。然而不能执行138~140，因为136,137并没有被选定。然后，leader可以发起请求，请求136、137执行。为了弥补136,137的鸿沟，我们立即提案一个无操作命令（no-op），使系统状态无变化。一旦136,137的无操作被选择，后续的138~140将继续执行  

到现在1~140命令都被选择。leader对大于140的实例，也完成了第1阶段，可以自由的开始第2阶段。它将执行客户端的命令141，随后执行141实例的第2阶段。之后是142，以此类推  

leader在141命令被选择之前，就可以提议142命令。它提交的141提案的所有消息都可能丢失，因此142命令的选择可能提前于141。当leader没有收到141实例阶段2的反馈时，它将重传这些消息。最终仍然可能失败，形成一个命令选择的鸿沟。

**leader选举**
当leader失败时，需要重新选举新leader，需要在算法中额外消耗阶段2中的资源。算法中在阶段2会尽量小消耗算法资源，以确保算法高效优化  

假设正常情况下，系统中仅有一个leader，只有在某些特殊情况下，如当前leader失效，系统正在选举新leader时例外。

在异常情况下，leader选举也会失败。如果没有主机充当leader，则没有新提案被提交。如果多个主机都认为自己是leader，他们将会以相同的实例提交提案值。这样任何一个提案都不会被接受。因此要确保系统中只有一个leader以保证系统向前推进  

在系统主机发生变化时，需要有一种决定机制，决定算法什么主机实现什么实例。最简单的方式是通过状态机本身实现。现有主机集合科研是状态的一部分，可以通过正常的状态机命令修改状态。可以让leader率先获取α各命令，让集群中的主机执行通过执行第i个状态机命令来执行i+α个实例的目标。这种思想可以通过一种强制的复杂的重配置算法实现  

--EOF--

参考文献
[1] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson. Impossibility
of distributed consensus with one faulty process. Journal of the ACM,
32(2):374–382, April 1985.
[2] Idit Keidar and Sergio Rajsbaum. On the cost of fault-tolerant consensus
when there are no faults—a tutorial. TechnicalReport MIT-LCS-TR-821,
Laboratory for Computer Science, Massachusetts Institute Technology,
Cambridge, MA, 02139, May 2001. also published in SIGACT News
32(2) (June 2001).
[3] Leslie Lamport. The implementation of reliable distributed multiprocess
systems. Computer Networks, 2:95–114, 1978.
[4] Leslie Lamport. Time, clocks, and the ordering of events in a distributed
system. Communications of the ACM, 21(7):558–565, July 1978.
[5] Leslie Lamport. The part-time parliament. ACM Transactions on Computer Systems, 16(2):133–169, May 1998

